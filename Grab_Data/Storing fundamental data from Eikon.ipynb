{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This file reads in a list of tickers, gets the correct Eikon name of the ticker, reads in fundamental quarterly data for the list of tickers, and does some intial clean up of the data read in. All data is then stored in csvs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import eikon as ek\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import bs4 as bs\n",
    "import requests\n",
    "import urllib2\n",
    "\n",
    "ek.set_app_id('DeNovoQuantFund')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock List\n",
    "Different functions for pulling stock tickers from different sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of S&P 500 tickers\n",
    "\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class':'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker)\n",
    "        \n",
    "    \n",
    "    return tickers\n",
    "\n",
    "ticker_list = save_sp500_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ticker_list = pd.read_csv('/Users/paindox/Documents/Udemy Apps/DeNovo Quant Fund Stuff/Eikon_Datasets/NYSE_Ticker_Symbols.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get tickers from NASDAQ text file.\n",
    "NASDAQ_tickers = open(\"/Users/paindox/Documents/Udemy Apps/DeNovo Quant Fund Stuff/Eikon_Datasets/nasdaqlisted.txt\",\"r\")\n",
    "lines = NASDAQ_tickers.readlines()\n",
    "ticker_list = []\n",
    "N = len(lines)\n",
    "for i, line in enumerate(lines):\n",
    "    if i > 0 and i < N:\n",
    "        ticker_list.append(line.split(\"|\")[0])\n",
    "NASDAQ_tickers.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Only run for certain files.\n",
    "ticker_list = np.array(ticker_list['Symbol'],dtype=np.string0)\n",
    "ticker_list = [tic for tic in ticker_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ticker_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting relevant fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of fields to add:\n",
    "Fundamental Data\n",
    "Numerical Data\n",
    "[\n",
    "ek.TR_Field('TR.DilutedEpsInclExtra'),\n",
    "ek.TR_Field('TR.RevenuePerShare'),\n",
    "ek.TR_Field('TR.BookValuePerShare'),\n",
    "ek.TR_Field('TR.DPSMean'),\n",
    "ek.TR_Field('TR.EBITMarginPercent'),\n",
    "ek.TR_Field('TR.TotalLongTermDebt'),\n",
    "ek.TR_Field('TR.EBIT'),\n",
    "ek.TR_Field('TR.PriceClose'),\n",
    "ek.TR_Field('TR.PriceClose.date')\n",
    "ek.TR_Field('TR.PE.date'),\n",
    "ek.TR_Field('TR.DPSActValue'),\n",
    "ek.TR_Field('TR.DilutedEpsExclExtra'),\n",
    "ek.TR_Field('TR.TtlDebtToTtlEquityPct'), \n",
    "ek.TR_Field('TR.EBITMarginPercent'),\n",
    "ek.TR_Field('TR.ROATotalAssetsPercent'),\n",
    "ek.TR_Field('TR.TotalDebtToEV'),\n",
    "ek.TR_Field('TR.TotalDebtToEBITDA')\n",
    "ek.TR_Field('TR.OperatingIncome'),\n",
    "ek.TR_Field('TR.Revenue'),\n",
    "ek.TR_Field('TR.NormIncAvailToCommon'),\n",
    "ek.TR_Field('TR.GrossDividendsCmnStock'),\n",
    "ek.TR_Field('TR.TotalCurrentAssets'),\n",
    "ek.TR_Field('TR.TotalCurrLiabilities'),\n",
    "ek.TR_Field('TR.TotalAssetsReported'),\n",
    "ek.TR_Field('TR.TotalLiabilities'),\n",
    "ek.TR_Field('TR.TotalLongTermDebt'),\n",
    "ek.TR_Field('TR.TotalEquity'),\n",
    "ek.TR_Field('TR.EBIT'),\n",
    "ek.TR_Field('TR.NetIncomeBeforeTaxes'),\n",
    "ek.TR_Field('TR.OperatingIncome'),\n",
    "ek.TR_Field('TR.OperatingExpense'),\n",
    "ek.TR_Field('TR.CostOfRevenueTotal'),\n",
    "ek.TR_Field('TR.GrossMargin'),\n",
    "ek.TR_Field('TR.OperatingMarginPercent'),\n",
    "ek.TR_Field('TR.TotalDebtOutstanding'),\n",
    "ek.TR_Field('TR.TotalInventory'),\n",
    "ek.TR_Field('TR.CashAndSTInvestments'),\n",
    "ek.TR_Field('TR.TotalReceivablesNet'),\n",
    "ek.TR_Field('TR.TRBCEconomicSector'),\n",
    "ek.TR_Field('TR.PropertyPlantEquipmentTotalNet'),\n",
    "ek.TR_Field('TR.GoodwillNet'),\n",
    "ek.TR_Field('TR.TangibleBVPS'),\n",
    "ek.TR_Field('TR.PriceTargetMean'),\n",
    "ek.TR_Field('TR.NumberOfAnalysts'),\n",
    "ek.TR_Field('TR.QuickRatio'),\n",
    "ek.TR_Field('TR.CurrentRatio')\n",
    "]\n",
    "\n",
    "Categorical Data\n",
    "[ek.TR_Field('TR.TRBCEconomicSector'),\n",
    "ek.TR_Field('TR.CommonName'),\n",
    "ek.TR_Field('TR.HeadquartersCountry'),\n",
    "ek.TR_Field('TR.ExchangeName')\n",
    "]\n",
    "\n",
    "Technical Daily Data\n",
    "[\n",
    "ek.TR_Field('TR.EVToSales'),\n",
    "ek.TR_Field('TR.PE'),\n",
    "ek.TR_Field('TR.PriceToSalesPerShare'),\n",
    "ek.TR_Field('TR.PriceToBVPerShare'),\n",
    "ek.TR_Field('TR.PriceToCFPerShare'),\n",
    "ek.TR_Field('TR.TotalDebtToEBITDA'),\n",
    "ek.TR_Field('TR.TotalDebtToEV'),\n",
    "ek.TR_Field('TR.PricePctChg1D'),\n",
    "ek.TR_Field('TR.PricePctChg2D'),\n",
    "ek.TR_Field('TR.PricePctChg5D'),\n",
    "ek.TR_Field('TR.PricePctChg4W'),\n",
    "ek.TR_Field('TR.PricePctChg4M'),\n",
    "ek.TR_Field('TR.PricePctChg8M'),\n",
    "ek.TR_Field('TR.PricePctChg11M'),\n",
    "ek.TR_Field('TR.Volume'),\n",
    "ek.TR_Field('TR.AvgDailyVolume120D'),\n",
    "ek.TR_Field('TR.AvgDailyVolume250D'),\n",
    "ek.TR_Field('TR.PriceAvg100D'),\n",
    "ek.TR_Field('TR.PriceAvg250D'),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of pertinant numerical fields\n",
    "numerical_fields = [\n",
    "ek.TR_Field('TR.DilutedEpsInclExtra'),\n",
    "ek.TR_Field('TR.RevenuePerShare'),\n",
    "ek.TR_Field('TR.BookValuePerShare'),\n",
    "ek.TR_Field('TR.DPSMean'),\n",
    "ek.TR_Field('TR.EBITMarginPercent'),\n",
    "ek.TR_Field('TR.TotalLongTermDebt'),\n",
    "ek.TR_Field('TR.EBIT'),\n",
    "ek.TR_Field('TR.PriceClose'),\n",
    "ek.TR_Field('TR.PriceClose.date'),\n",
    "ek.TR_Field('TR.DPSActValue'),\n",
    "ek.TR_Field('TR.DilutedEpsExclExtra'),\n",
    "ek.TR_Field('TR.TtlDebtToTtlEquityPct'), \n",
    "ek.TR_Field('TR.EBITMarginPercent'),\n",
    "ek.TR_Field('TR.ROATotalAssetsPercent'),\n",
    "ek.TR_Field('TR.OperatingIncome'),\n",
    "ek.TR_Field('TR.TotalRevenue'),\n",
    "ek.TR_Field('TR.NormIncAvailToCommon'),\n",
    "ek.TR_Field('TR.GrossDividendsCmnStock'),\n",
    "ek.TR_Field('TR.TotalCurrentAssets'),\n",
    "ek.TR_Field('TR.TotalCurrLiabilities'),\n",
    "ek.TR_Field('TR.TotalAssetsReported'),\n",
    "ek.TR_Field('TR.TotalLiabilities'),\n",
    "ek.TR_Field('TR.TotalLongTermDebt'),\n",
    "ek.TR_Field('TR.TotalEquity'),\n",
    "ek.TR_Field('TR.EBIT'),\n",
    "ek.TR_Field('TR.NetIncomeBeforeTaxes'),\n",
    "ek.TR_Field('TR.OperatingIncome'),\n",
    "ek.TR_Field('TR.OperatingExpenses'),\n",
    "ek.TR_Field('TR.CostOfRevenueTotal'),\n",
    "ek.TR_Field('TR.GrossMargin'),\n",
    "ek.TR_Field('TR.OperatingMarginPercent'),\n",
    "ek.TR_Field('TR.TotalDebtOutstanding'),\n",
    "ek.TR_Field('TR.TotalInventory'),\n",
    "ek.TR_Field('TR.CashAndSTInvestments'),\n",
    "ek.TR_Field('TR.TotalReceivablesNet'),\n",
    "ek.TR_Field('TR.TRBCEconomicSector'),\n",
    "ek.TR_Field('TR.PropertyPlantEquipmentTotalNet'),\n",
    "ek.TR_Field('TR.GoodwillNet'),\n",
    "ek.TR_Field('TR.TangibleBVPS'),\n",
    "ek.TR_Field('TR.PriceTargetMean'),\n",
    "ek.TR_Field('TR.NumberOfAnalysts'),\n",
    "ek.TR_Field('TR.QuickRatio'),\n",
    "ek.TR_Field('TR.CurrentRatio')\n",
    "]\n",
    "\n",
    "numerical_fields.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of pertinant categorical fields\n",
    "categorical_fields = [ek.TR_Field('TR.TRBCEconomicSector'),\n",
    "ek.TR_Field('TR.CommonName'),\n",
    "ek.TR_Field('TR.HeadquartersCountry'),\n",
    "ek.TR_Field('TR.ExchangeName')\n",
    "]\n",
    "\n",
    "categorical_fields.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Eikon Tickers\n",
    "Tickers read from files don't have the proper Eikon extensions. This function tries to find the appropriate Eikon extension for each ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting correct ticker name\n",
    "def get_eikon_ticker_name(ticker,f = [ek.TR_Field('TR.RevenuePerShare')], end_date = '2019-01-01'):\n",
    "\n",
    "    ticker = str(ticker)\n",
    "    ticker1 = str(ticker)\n",
    "    \n",
    "    ticker = ticker1 + '.O'\n",
    "    df_fundamental, err = ek.get_data([ticker], fields= f,parameters={'SDate':'2017-01-01', 'EDate': end_date,\n",
    "                                                                      'Frq': 'D'})\n",
    "    if err is None:\n",
    "        return ticker\n",
    "\n",
    "    ticker = ticker1 + '.OQ'\n",
    "    df_fundamental, err = ek.get_data([ticker], fields= f,parameters={'SDate':'2017-01-01', 'EDate': end_date, \n",
    "                                                                      'Frq': 'D'})\n",
    "    if err is None:\n",
    "        return ticker\n",
    "    \n",
    "    ticker = ticker1 + '.TO'\n",
    "    df_fundamental, err = ek.get_data([ticker], fields= f,parameters={'SDate':'2017-01-01', 'EDate': end_date, \n",
    "                                                                      'Frq': 'D'})\n",
    "    if err is None:\n",
    "        return ticker\n",
    "\n",
    "    ticker = ticker1 + '.N'\n",
    "    df_fundamental, err = ek.get_data([ticker], fields= f,parameters={'SDate':'2017-01-01', 'EDate': end_date, \n",
    "                                                                      'Frq': 'D'})\n",
    "    if err is None:\n",
    "        return ticker\n",
    "    \n",
    "    ticker = ticker1\n",
    "    df_fundamental, err = ek.get_data([ticker], fields= f,parameters={'SDate':'2017-01-01', 'EDate': '2018-01-01'})\n",
    "\n",
    "    if err is None:\n",
    "        return ticker\n",
    "\n",
    "    print('Ticker {} not found'.format(ticker1))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Fundamental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting Data for Analysis\n",
    "\n",
    "def get_fundamental_data(ticker, f,f1, start_date1, end_date1):\n",
    "    \n",
    "    try:\n",
    "        # Grab numerical data for each quarter.\n",
    "        df_fundamentals,err = ek.get_data([ticker], fields= f,parameters={'SDate': start_date1, 'EDate': end_date1,\n",
    "                                                                'Period':'FQ0',\n",
    "                                                               'Frq': 'FQ' })\n",
    "        # Grab categorical data for each quarter.\n",
    "        sector, err = ek.get_data([ticker], f1)\n",
    "        \n",
    "        df_fundamentals = df_fundamentals.merge(sector,how='left', on='Instrument')\n",
    "        \n",
    "        return(df_fundamentals)\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        print('Error for {}'.format(ticker))\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting Start and End Dates\n",
    "\n",
    "start_date = dt.datetime(1990,1,1)\n",
    "end_date = dt.datetime.today()\n",
    "start_date1 = start_date.strftime('%Y-%m-%d')\n",
    "end_date1 = end_date.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating fundamentals dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_fund_data(final_file, file_name):\n",
    "    df_fundamentals = final_file\n",
    "    df_fundamentals.sort_values(by= ['Instrument','Date'],inplace=True)\n",
    "    \n",
    "    # Handling missing dividend data\n",
    "    df_fundamentals['Has Div'] = 0\n",
    "    df_fundamentals.loc[df_fundamentals['Dividend Per Share - Mean'].isnull() == False, 'Has Div'] = 1\n",
    "    \n",
    "    # Fill nas with zero for dividends\n",
    "    df_fundamentals['Dividend Per Share - Mean']= np.nan_to_num(df_fundamentals['Dividend Per Share - Mean'])\n",
    "\n",
    "    # Write data to csv.\n",
    "    df_fundamentals.to_csv(file_name)\n",
    "    print(\"File Printed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_file = None\n",
    "cur_file = None\n",
    "write_file = False\n",
    "for i,tick in enumerate(ticker_list):\n",
    "    \n",
    "    # Write data to csv every 500 iterations.\n",
    "    # Flag used in case on the 500th iteration the API call fails.\n",
    "    # Want to make it so the current dataframe is written on the next successsful API call.\n",
    "    if i > 0 and i % 500 == 0:\n",
    "        write_file = True\n",
    "    try:\n",
    "        tick = get_eikon_ticker_name(tick, end_date = end_date1)\n",
    "        if tick:\n",
    "            cur_file = get_fundamental_data(tick, numerical_fields, categorical_fields,\n",
    "                                            start_date1, end_date1)\n",
    "\n",
    "        if (final_file is None and isinstance(cur_file, pd.DataFrame)):\n",
    "            final_file = cur_file\n",
    "        \n",
    "        # Write to csv evey 500 tickers, if the final_file dataframe is populated.\n",
    "        elif (write_file and isinstance(final_file, pd.DataFrame)):\n",
    "            write_file = False\n",
    "            file_name = '/Users/paindox/Documents/Udemy Apps/DeNovo Quant Fund Stuff/Eikon_Datasets/NASDAQ_2019_Fund_Data/NASDAQ_fund_data_{}.csv'.format(i)\n",
    "            write_fund_data(final_file, file_name)\n",
    "            if isinstance(cur_file, pd.DataFrame):\n",
    "                final_file = cur_file\n",
    "            else:\n",
    "                final_file = None\n",
    "\n",
    "        elif (isinstance(cur_file, pd.DataFrame)):\n",
    "            final_file = final_file.append(cur_file, ignore_index = True)\n",
    "\n",
    "    except urllib2.HTTPError as err:\n",
    "        print('HTTPError for tick {}'.format(tick))\n",
    "        print('Error message: {}'.format(err))\n",
    "    except:\n",
    "        print('Some error occurred for tick {}.'.format(tick))\n",
    "    \n",
    "   \n",
    "    print(i)\n",
    "\n",
    "if isinstance(final_file, pd.DataFrame): \n",
    "    file_name = '/Users/paindox/Documents/Udemy Apps/DeNovo Quant Fund Stuff/Eikon_Datasets/NASDAQ_2019_Fund_Data/NASDAQ_fund_data_{}.csv'.format(len(ticker_list))\n",
    "    write_fund_data(final_file, file_name)\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Already done above now.\n",
    "\n",
    "### Handling all remaining NA data ###\n",
    "# Leaving this for later cleanup.\n",
    "# df_fundamentals.dropna(inplace= True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
