steps:
  - name: gcr.io/cloud-builders/gcloud
    args:
      - dataproc
      - clusters
      - create
      - auto-cluster
      - --scopes=cloud-platform
      - --region=us-central1
      - --zone=us-central1-a
      - --bucket=pyspark_bucket
      - --max-idle=1h
      - --image-version=1.4
      - --optional-components=ANACONDA,JUPYTER
      - --num-masters=1
      - --num-workers=4
      - --master-machine-type=n1-highmem-16
      - --master-boot-disk-type=pd-ssd
      - --master-boot-disk-size=400GB
      - --worker-machine-type=n1-highmem-16
      - --worker-boot-disk-size=400GB
      - --worker-boot-disk-type=pd-ssd
      - --preemptible-worker-accelerator type=nvidia-tesla-k80,count=5
      - --initialization-actions gs://dataproc-initialization-actions/python/conda-install.sh,gs://dataproc-initialization-actions/python/pip-install.sh,gs://seng550/bash_scripts/install_gpu_driver.bash \
      - --metadata=CONDA_PACKAGES=tensorflow keras
      - --metadata=PIP_PACKAGES=numpy==1.17.3 pandas==0.25.3 scipy==1.3.2 elephas systemml sklearn talos prompt_toolkit
  - name: gcr.io/cloud-builders/gcloud
    args:
      - dataproc
      - jobs
      - submit
      - pyspark
      - gcp_scripts/check_python_env.py
      - --cluster=auto-cluster
      - --region=us-central1
      - --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar
  - name: gcr.io/cloud-builders/gcloud
    args:
      - dataproc
      - jobs
      - submit
      - pyspark
      - data_cleaning/stats_clean_join.py
      - --cluster auto-cluster
      - --region us-central1
      - --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar
  - name: gcr.io/cloud-builders/gcloud
    args:
      - dataproc
      - jobs
      - submit
      - pyspark
      - models/k_means_on_fundamentals.py
      - --cluster auto-cluster
      - --region us-central1
      - --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar
  - name: gcr.io/cloud-builders/gcloud
    args:
      - dataproc
      - jobs
      - submit
      - pyspark
      - models/binning_k_means_results.py
      - --cluster auto-cluster
      - --region us-central1
      - --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar
  - name: gcr.io/cloud-builders/gcloud
    args:
      - dataproc
      - jobs
      - submit
      - pyspark
      - models/Linear_Regressor.py
      - --cluster auto-cluster
      - --region us-central1
      - --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar
  - name: gcr.io/cloud-builders/gcloud
    args:
      - dataproc
      - jobs
      - submit
      - pyspark
      - models/Dense_Neural_Net.py
      - --cluster auto-cluster
      - --region us-central1
      - --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar
  - name: gcr.io/cloud-builders/gcloud
    args:
      - dataproc
      - jobs
      - submit
      - pyspark
      - models/graham_metrics.py
      - --cluster auto-cluster
      - --region us-central1
      - --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar
  - name: gcr.io/cloud-builders/gcloud
    args:
      - dataproc
      - jobs
      - submit
      - pyspark
      - models/stock_pred_lstm_on_per_company_basis.py
      - --cluster auto-cluster
      - --region us-central1
      - --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar
  - name: gcr.io/cloud-builders/gcloud
    args:
      - dataproc
      - clusters
      - delete
      - auto-cluster
      - --region=us-central1
